{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0407a1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 09:32:24.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtime_series.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mPROJ_ROOT path is: /home/james/Repo/PhD Repo/time_series_clustering\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from time_series.data_generators import LorenzGenerator\n",
    "from time_series.time_series_models import KernelRidgeRegression, MovingAverageEstimator\n",
    "from time_series.kernels import GaussianKernel\n",
    "from time_series.evaluators.mse_one_step import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f081d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/Repo/PhD Repo/time_series_clustering/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c859c0",
   "metadata": {},
   "source": [
    "# Config parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8c4a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"experiment.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9eb1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "defintitions_conf = config[\"definitions\"]\n",
    "experiments_conf = config[\"experiments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc85b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions = dict()\n",
    "for k, conf in defintitions_conf.items():\n",
    "    if k == \"datasets\":\n",
    "        datasets = dict()\n",
    "        for d, v  in conf.items():\n",
    "            datasets[d] = dict()\n",
    "            if v[\"generator\"] == \"Lorenz\":\n",
    "                datasets[d][\"generator\"] = LorenzGenerator\n",
    "            if \"parameters\" in v:\n",
    "                datasets[d][\"parameters\"] = v[\"parameters\"]    \n",
    "            else:\n",
    "                datasets[d][\"parameters\"] = {}\n",
    "        definitions[k] = datasets\n",
    "\n",
    "    elif k == \"models\":\n",
    "        models = dict()\n",
    "        for m, v  in conf.items():\n",
    "            models[m] = dict()\n",
    "            if v[\"model\"] == \"KernelRidgeRegression\":\n",
    "                models[m][\"model\"] = KernelRidgeRegression\n",
    "                \n",
    "            if \"parameters\" in v:\n",
    "                models[m][\"parameters\"] = v[\"parameters\"]\n",
    "            else:\n",
    "                models[m][\"parameters\"] = {}\n",
    "\n",
    "            if \"hyperparameters\" in v:\n",
    "                models[m][\"hyperparameters\"] = v[\"hyperparameters\"]\n",
    "\n",
    "        definitions[k] = models\n",
    "\n",
    "    elif k == \"kernels\":\n",
    "        kernels = dict()\n",
    "        for i, v  in conf.items():\n",
    "            kernels[i] = dict()\n",
    "            if v[\"kernel\"] == \"GaussianKernel\":\n",
    "                kernels[i][\"kernel\"] = GaussianKernel\n",
    "                \n",
    "            if \"parameters\" in v:\n",
    "                kernels[i][\"parameters\"] = v[\"parameters\"]\n",
    "            else:\n",
    "                kernels[i][\"parameters\"] = {}\n",
    "\n",
    "            if \"hyperparameters\" in v:\n",
    "                kernels[i][\"hyperparameters\"] = v[\"hyperparameters\"]\n",
    "\n",
    "        definitions[k] = kernels\n",
    "    \n",
    "    elif k == \"evaluators\":\n",
    "        evaluators = dict()\n",
    "        for i, v  in conf.items():\n",
    "            evaluators[i] = dict()\n",
    "            if v[\"evaluator\"] == \"MeanSquaredError\":\n",
    "                evaluators[i][\"evaluator\"] = MeanSquaredError\n",
    "                \n",
    "            if \"parameters\" in v:\n",
    "                evaluators[i][\"parameters\"] = v[\"parameters\"]\n",
    "            else:\n",
    "                evaluators[i][\"parameters\"] = {}\n",
    "        definitions[k] = evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19464ab",
   "metadata": {},
   "source": [
    "# Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8222b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesData:\n",
    "    def __init__(self, X, y=None, train_val_test_split=None, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        self.N = len(X)\n",
    "        self.indices = np.arange(self.N)\n",
    "        self.tvt_split = train_val_test_split\n",
    "\n",
    "    def train_data(self):\n",
    "        train_idx = self.indices[:int(self.tvt_split[0]*self.N)]\n",
    "\n",
    "        if type(self.y) == type(None):\n",
    "            return self.X[train_idx], None\n",
    "\n",
    "        return self.X[train_idx], self.y[train_idx]\n",
    "\n",
    "    def val_data(self, lag=0):\n",
    "        val_idx = self.indices[int(self.tvt_split[1]*self.N) - lag:int(self.tvt_split[2]*self.N)]\n",
    "\n",
    "        if type(self.y) == type(None):\n",
    "            return self.X[val_idx], None\n",
    "\n",
    "        return self.X[val_idx], self.y[val_idx]\n",
    "\n",
    "    def test_data(self, lag=0):\n",
    "        test_idx = self.indices[int(self.tvt_split[2]*self.N)-lag:]\n",
    "\n",
    "        if type(self.y) == type(None):\n",
    "            return self.X[test_idx], None\n",
    "\n",
    "        return self.X[test_idx], self.y[test_idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158c1d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_datasets(datasets):\n",
    "    \"\"\"\n",
    "    Defines an iterator over the datasets specified in the config. \n",
    "    \"\"\"\n",
    "    for dataset_name, dataset_confs in datasets.items():\n",
    "        dataset_def = definitions[\"datasets\"][dataset_name]\n",
    "\n",
    "        if \"train_val_test_split\" in dataset_confs:\n",
    "            tvt_split = dataset_confs[\"train_val_test_split\"]\n",
    "        else:\n",
    "            tvt_split = [1]\n",
    "\n",
    "        result = dict(\n",
    "            dataset=dataset_name,\n",
    "            train_test_val_split = tvt_split,\n",
    "            sweep_vals=None,\n",
    "            parameters=dict(dataset_def[\"parameters\"])\n",
    "        )\n",
    "\n",
    "        if \"parameters\" in dataset_confs:\n",
    "            for param, value in dataset_confs[\"parameters\"].items():\n",
    "                result[\"parameters\"][param] = value\n",
    "\n",
    "        # Process overides\n",
    "        if \"sweeps\" in dataset_confs:\n",
    "            for sweep in dataset_confs[\"sweeps\"]:\n",
    "                sweep_result = dict(result)\n",
    "\n",
    "                sweep_val_names = []\n",
    "                sweep_values = []\n",
    "                for sweep_param, sweep_conf in dataset_confs[\"sweeps\"][sweep].items():\n",
    "                    sweep_vals = np.linspace(\n",
    "                        float(sweep_conf[\"min\"]), \n",
    "                        float(sweep_conf[\"max\"]), \n",
    "                        int(sweep_conf[\"N_steps\"])\n",
    "                    )\n",
    "                    sweep_val_names.append(sweep_param)\n",
    "                    sweep_values.append(sweep_vals)\n",
    "\n",
    "                # Combine the sweep values\n",
    "                all_combinations = itertools.product(*sweep_values)                \n",
    "                for combined_vals in all_combinations:\n",
    "                    for i, param in enumerate(sweep_val_names):\n",
    "                        sweep_result[\"parameters\"][param] = combined_vals[i]\n",
    "\n",
    "                    t, data = dataset_def[\"generator\"](**sweep_result[\"parameters\"])()\n",
    "                    sweep_result[\"data\"] = TimeSeriesData(\n",
    "                        t = t,\n",
    "                        X = data[:-1],\n",
    "                        y = data[1:],\n",
    "                        train_val_test_split=tvt_split\n",
    "                    )\n",
    "                    yield sweep_result\n",
    "        \n",
    "        else:\n",
    "            t, data = dataset_def[\"generator\"](**result[\"parameters\"])()\n",
    "            result[\"data\"] = TimeSeriesData(\n",
    "                t = t,\n",
    "                X = data[:-1],\n",
    "                y = data[1:],\n",
    "                train_val_test_split=tvt_split\n",
    "            )\n",
    "            yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "190aa582",
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment_name, experiment in experiments_conf.items():\n",
    "    # Process datasets\n",
    "    dataset_generator = iterate_datasets(experiment[\"datasets\"])\n",
    "    for dataset in dataset_generator:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99813be8",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c3f339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_confs in experiment[\"models\"].items():\n",
    "    model = definitions[\"models\"][model_name][\"model\"]\n",
    "    parameters = dict(definitions[\"models\"][model_name][\"parameters\"])\n",
    "\n",
    "    if \"hyperparameters\" in model_confs:\n",
    "        X_train, y_train = dataset[\"data\"].train_data()\n",
    "\n",
    "        if \"lag\" not in model_confs[\"hyperparameters\"]:\n",
    "            X_val, y_val = dataset[\"data\"].val_data()\n",
    "\n",
    "        evaluator = experiment[\"evaluators\"][\"hyperparameter_tuning\"]\n",
    "\n",
    "        def objective(trial):\n",
    "            params = dict(parameters)\n",
    "            for hparam, hparam_conf in model_confs[\"hyperparameters\"].items():\n",
    "                if hparam_conf[\"type\"] == float:\n",
    "                    params[hparam] = trial.suggest_float(\n",
    "                        hparam,\n",
    "                        hparam_conf[\"min\"],\n",
    "                        hparam_conf[\"max\"] \n",
    "                    )\n",
    "                elif hparam_conf[\"type\"] == int:\n",
    "                    params[hparam] = trial.suggest_int(\n",
    "                        hparam,\n",
    "                        hparam_conf[\"min\"],\n",
    "                        hparam_conf[\"max\"] \n",
    "                    )\n",
    "                else:\n",
    "                    raise ValueError(\"Expecting either int or float hyperparameter\")\n",
    "\n",
    "            test_model = model(**params)\n",
    "            test_model.fit(X_train, y_train)\n",
    "\n",
    "            if \"lag\" in params:\n",
    "                X_val, y_val = dataset[\"data\"].val_data(lag = params[\"lag\"])\n",
    "            \n",
    "            y_pred = test_model.predict(X_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # # Process kernels\n",
    "    # if \"kernels\" in model_confs:\n",
    "    #     kernels = []\n",
    "    #     for kernel_name in model_confs[\"kernels\"]:\n",
    "    #         kernel = definitions[\"kernels\"][kernel_name][\"kernel\"]\n",
    "    #         if \"parameters\" in definitions[\"kernels\"][kernel_name]:\n",
    "    #             kernel_params = dict(definitions[\"kernels\"][kernel_name][\"parameters\"])\n",
    "    #         else:\n",
    "    #             kernel_params = dict()\n",
    "    #         kernels.append(\n",
    "    #             definitions[\"kernels\"][kernel_name][\"kernel\"](**kernel_params)\n",
    "    #         )\n",
    "\n",
    "\n",
    "    # if \"parameters\" in model_confs:\n",
    "    #     parameters.update(model_confs[\"parameters\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f4330a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg': {'type': 'float', 'min': 1e-07, 'max': 0.01}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_confs[\"hyperparameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe05c5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernels': ['k1', 'k1', 'k1'],\n",
       " 'hyperparameters': {'reg': {'type': 'float', 'min': 1e-07, 'max': 0.01}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment[\"models\"][model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5e54445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_krr': {'model': time_series.time_series_models.kernel_ridge_regression.KernelRidgeRegression,\n",
       "  'parameters': {}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definitions[\"models\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa952a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'kernel': time_series.kernels.gaussian_kernel.GaussianKernel,\n",
       "  'parameters': {'bandwidth': 100}},\n",
       " {'kernel': time_series.kernels.gaussian_kernel.GaussianKernel,\n",
       "  'parameters': {'bandwidth': 100}},\n",
       " {'kernel': time_series.kernels.gaussian_kernel.GaussianKernel,\n",
       "  'parameters': {'bandwidth': 100}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[definitions[\"kernels\"][i] for i in model_confs[\"kernels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "891d9c43",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[32;43m1\u001b[39;49m\u001b[43m/\u001b[49m\u001b[32;43m0\u001b[39;49m\n",
      "\u001b[31mZeroDivisionError\u001b[39m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662a128",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GaussianKernel.__init__() missing 1 required positional argument: 'bandwidth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     13\u001b[39m             kernel_params = \u001b[38;5;28mdict\u001b[39m()\n\u001b[32m     14\u001b[39m         kernels.append(\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m             \u001b[43mdefinitions\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkernels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkernel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkernel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkernel_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m         )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mparameters\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_confs:\n\u001b[32m     20\u001b[39m     parameters.update(model_confs[\u001b[33m\"\u001b[39m\u001b[33mparameters\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mTypeError\u001b[39m: GaussianKernel.__init__() missing 1 required positional argument: 'bandwidth'"
     ]
    }
   ],
   "source": [
    "for model_name, model_confs in experiment[\"models\"].items():\n",
    "    model = definitions[\"models\"][model_name][\"model\"]\n",
    "    parameters = dict(definitions[\"models\"][model_name][\"parameters\"])\n",
    "\n",
    "    # Process kernels\n",
    "    if \"kernels\" in model_confs:\n",
    "        kernels = []\n",
    "        for kernel_name in model_confs[\"kernels\"]:\n",
    "            kernel = definitions[\"kernels\"][kernel_name][\"kernel\"]\n",
    "            if \"parameters\" in definitions[\"kernels\"][kernel_name]:\n",
    "                kernel_params = dict(definitions[\"kernels\"][kernel_name][\"parameters\"])\n",
    "            else:\n",
    "                kernel_params = dict()\n",
    "            kernels.append(\n",
    "                definitions[\"kernels\"][kernel_name][\"kernel\"](**kernel_params)\n",
    "            )\n",
    "\n",
    "\n",
    "    if \"parameters\" in model_confs:\n",
    "        parameters.update(model_confs[\"parameters\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d60340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k1': {'kernel': time_series.kernels.gaussian_kernel.GaussianKernel,\n",
       "  'parameters': None},\n",
       " 'k2': {'kernel': time_series.kernels.gaussian_kernel.GaussianKernel,\n",
       "  'parameters': None},\n",
       " 'k3': {'kernel': time_series.kernels.gaussian_kernel.GaussianKernel,\n",
       "  'parameters': None}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definitions[\"kernels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daafdea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'kernel': time_series.kernels.gaussian_kernel.GaussianKernel,\n",
       "  'parameters': None},\n",
       " {'kernel': time_series.kernels.gaussian_kernel.GaussianKernel,\n",
       "  'parameters': None},\n",
       " {'kernel': time_series.kernels.gaussian_kernel.GaussianKernel,\n",
       "  'parameters': None}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09a865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(time_series.time_series_models.kernel_ridge_regression.KernelRidgeRegression,\n",
       " {'reg': 0.01})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424ff3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernels': ['k1', 'k2', 'k3'], 'parameters': {'reg': 0.01}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffca414",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[32;43m1\u001b[39;49m\u001b[43m/\u001b[49m\u001b[32;43m0\u001b[39;49m\n",
      "\u001b[31mZeroDivisionError\u001b[39m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b984b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_configs():\n",
    "    pass\n",
    "\n",
    "def load_data():\n",
    "    pass\n",
    "\n",
    "def load_model():\n",
    "    pass\n",
    "\n",
    "def tune_parameters():\n",
    "    pass\n",
    "\n",
    "def train_final_model():\n",
    "    pass\n",
    "\n",
    "def evaluate_model():\n",
    "    pass\n",
    "\n",
    "def generate_reports():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2877350",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    pass\n",
    "\n",
    "    def run(self):\n",
    "        # Parse configs\n",
    "\n",
    "        # Load data\n",
    "\n",
    "        # Load model\n",
    "\n",
    "        # Tune parameters\n",
    "\n",
    "        # Train final model\n",
    "\n",
    "        # Evaluate model\n",
    "\n",
    "        # Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e85d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ffd1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa42ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
